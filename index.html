<!DOCTYPE html>
<html>
  <head>
  <title>Adrian de Wynter</title>
  
  <meta name="google-site-verification" content="UhAhnWA093u8hR6zIezUozC_aTIl1dT1rPX8UEuOdDg" />
  <meta content="Adrian de Wynter" name="author">
  <meta name="keywords" content="Adrian, de Wynter, Adrian de Wynter">
  <meta name="description" content="Adrian de Wynter's home page, updated every two years!">
  <meta content="width=device-width, initial-scale=1.0, user-scalable=no" name="viewport">
  
  <link href="styles/main_index.css" media="screen" rel="stylesheet" type="text/css">
  <link rel="icon" type="image/png" href="img/dewynter.jpg"/>

  </head>

<!-- very loosely taken from Ana Enders' design -- anaenders.com -->
  <body>
    <div class="content">

      <div class="header-wrapper">
        <header>
          <div style="display: flex; justify-content: center; text-align: center; align-items: center;"><h1>Adrian de Wynter</h1>
             
            <p> <br/><br/>.</p>
          </div>
        </header>
      </div>

      <div>
        <div class="banner">
          <ul>
            <li class="slide2"></li>
            <li class="slide1"></li>
          </ul>
        </div>
        <div class="banner2">
          <ul>
          <li class="mslide1"></li>
          <li class="mslide2"></li>
        </ul>
        </div>

        <div class="main-text">
          <div class="about">
            <div class="about-text">

              <p style="font-family:helvetica">I am a principal applied <b>scientist</b> at Microsoft and a <b>researcher</b> (PGR) at the University of York. I work in projects related to natural language understanding/generation and fundamental problems in AI, such as <b>reasoning and formal modelling of dialogue</b>, like LLMs.</p>

              <p style="font-family:helvetica">At Microsoft my work involves leading, designing, and deploying Word- and Office- AI features and research. These deal with composition (what you see when you type in Word), multilinguality (e.g., expanding products to new markets), measurement (reasoning, automated evaluation), personalisation, and other workstreams. Yes, I also work on buzzwords like 'agentic workflows'. Most of the work here, you can see it in Word Copilot.</p>

              <p style="font-family:helvetica">My primary research interest is <b>reasoning as it relates to language in humans and machines</b>. Lately I have focused on LLM-based reasoning capabilities (e.g. <a href="https://ojs.aaai.org/index.php/AAAI/article/view/35011">here</a>, <a href="https://arxiv.org/abs/2507.01936">here</a>, and <a href="https://arxiv.org/abs/2404.01230">here</a>). 
              My theoretical work is intuitionistic: algorithms have guarantees of complexity and convergence via <em>constructive proofs</em>, and must relate to a <em>realistic</em> (e.g. production) scenario. This gives <b>meaningful answers about complex problems</b>.</p>
            </div>

            <div class="about-text">
              <p style="font-family:helvetica">For example, we used <a href="https://arxiv.org/abs/2312.06562">category theory</a> to prove that <b>some prompting strategies are objectively better than others</b>; and that they would produce more preferrable outcomes by users (and ended up being a product in Word). I also recently wrote <a href="https://arxiv.org/abs/2506.03083">an algorithm</a> with cryptographic guarantees for determining <b>trust in LLMs-as-judges</b>.</p>

              <p style="font-family:helvetica">In earlier work I <a href="https://arxiv.org/abs/1908.09942">showed</a> that finding a globally optimal solution to model compression is undecidable, but <a href="https://arxiv.org/abs/2010.08512">proved</a> that polynomial-time approximation algorithms exist--and <a href="https://arxiv.org/abs/2010.10499">applied</a> these results to BERT and reaching a (then) state-of-the-art on model compression. This last contribution was later adapted for quantum circuit optimisation in <a href="https://github.com/XanaduAI/QHack2021/issues/73">work</a> at ORNL.
                I also showed (bridging learning theory and topological data analysis) how (and when) <a href="https://link.springer.com/article/10.1007/s41884-024-00153-0">LLM-based data augmentation</a> works.</p>

              <p style="font-family:helvetica">My other research interests relate to <b>recreational mathematics</b> (games), <b>preserving endangered languages</b>, and <b>computational social science</b>. In the latter I have worked on mitigating <a href="https://ojs.aaai.org/index.php/AAAI/article/view/35011">toxicity</a>, <a href="https://arxiv.org/abs/2410.11005">unfairness</a>, and <a href="https://arxiv.org/abs/2503.20302">other</a> harms of LLMs; <a href="https://arxiv.org/abs/2408.15409">research on LLM research</a>; and worked on the first study of the impact of ChatGPT on <a href="https://arxiv.org/abs/2412.01617">loneliness</a>. And I also publish in <a href="https://sigbovik.org/2025/proceedings.pdf">SIGBOVIK</a>, because this job is actually fun.</p>

              <p>I have served as reviewer for AAAI, EMNLP, and so on. I also review for Nature (Communications, Artificial Intelligence), IEEE Transactions on Games, ACM TIST; and I am now on <a href="https://x.com/deWynterruption">Twitter</a>.</p>

              <p style="font-family:Helvetica, Serif; color: #231f20; display:flex; justify-content:flex-end">Last updated: August '25.</p>
            </div>
          </div>


          <div class="papers">
              <div class="papers-block">
                <div class="section-label--right">TL;DRs of Some Papers</div>

                <div class="papers-education--desktop">

                  <div>
                    <p></p>
                    <p style="font-family:helvetica"><i>I've found it useful to have a series of posts about some of my works. This makes them more accessible and allows me to share my passion for mathematics. I definitely do not proofread these.
                    <br>I'm absolutely terrible at updating this site (record: 2 years), so bear with me.</i></p>
                  </div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b><a href="https://adewynter.github.io/notes/nodata.html">The No-Data Algorithm</a></b>
                    </div>
                    <div class="paper-misc">
                      How to enable trust in LLMs-as-judges WITHOUT labelled data! With proofs!
                    </div>
                  </div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b><a href="https://adewynter.github.io/Doom.html">Will GPT-4 Run DOOM?</a></b>
                    </div>
                    <div class="paper-misc">
                      Yes but no. 
                      Links to code, resources, TL;DR of the paper, and videos of the model playing the game.
                    </div>
                  </div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b><a href="https://adewynter.github.io/notes/civ_utms.html">Turing Completeness and Sid Meier's Civilization</a></b>
                    </div>
                    <div class="paper-misc">
                    Building a literal computer inside Civ
                    </div>
                  </div>


                  <div class="section-item">
                    <div class="paper-title">
                      <b><a href="https://adewynter.github.io/notes/decidability_of_nas.html">Neural architecture search is undecidable</a></b>
                    </div>
                    <div class="paper-misc">
                   <!-- A post on how hard neural architecture search (NAS) and machine learning can be, from a computational perspective. It also discusses the workarounds and applications of this result, with a particular emphasis on why some NAS approaches do not do better than random search. -->
                   A summary of my poorly-titled, ever-misinterpreted paper 'On The Bounds of Function Approximations.' 
                    </div>
                  </div>


                  <div class="section-item">
                    <div class="paper-title">
                      <b><a href="https://adewynter.github.io/notes/bort_algorithms_and_applications.html">Bort</a></b>
                    </div>
                    <div class="paper-misc">
                      (Provably) optimal model compression with algebraic topology
                      <!--
                      A post on the algorithms used to obtain Bort, an optimally compressed version of the BERT language model. This can be viewed as a summary of my papers "Optimal Subarchitecture Extraction for BERT", "An Algorithm for Learning Smaller Representations of Models With Scarce Data", and "An Approximation Algorithm for Optimal Subarchitecture Extraction", albeit less concise than these titles, if you can believe it. -->
                    </div>
                  </div>


              </div><!-- media-education--desktop -->

            </div><!-- media-filler -->


          </div><!-- media -->



          <div class="papers">

              <div class="papers-block">
                <div class="section-label--right">New and Selected Works</div>
                <div class="papers-education--desktop">

                  <div><p></p><p style="font-family: Helvetica"><i>Following Larry Wasserman's <a href="http://stat.cmu.edu/~larry/Peer-Review.pdf">essay</a>, I invite comments on the papers below. Feel free to email me.<br>For a longer, complete list of works see <a href="notes/older_papers.html">here</a>.<br>For how to handle my last name's weird spelling rules, see <a href="notes/tussenvoegsels.html">here</a>.</i></p></div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b>Evaluating Style-Personalized Text Generation: Challenges and Directions</b>
                    </div>
                    <div class="paper-misc">
                      <a href="https://arxiv.org/abs/2508.06374">[pdf]</a>
                      <!-- <a href="bibtex/thinline.html">[BibTex]</a></b> -->
                      </div>
                    <div class="paper-authors">
                      Anubhav Jangra, Bahareh Sarrafzadeh, Adrian de Wynter, Silviu Cucerzan, and Sujay Kumar Jauhar
                    </div>
                    <div class="paper-misc">
                      Forthcoming
                    </div>
                  </div>


                  <div class="section-item">
                    <div class="paper-title">
                      <b>The Thin Line Between Comprehension and Persuasion in LLMs</b>
                    </div>
                    <div class="paper-misc">
                      <a href="https://arxiv.org/abs/2507.01936">[pdf]</a>
                      <a href="bibtex/thinline.html">[BibTex]</a></b>
                      <a href="https://github.com/adewynter/the_thin_line">[Code]</a></b>
                    </div>
                    <div class="paper-authors">
                      Adrian de Wynter and Tangming Yuan
                    </div>
                    <div class="paper-misc">
                      Preprint
                    </div>
                  </div>


                  <div class="section-item">
                    <div class="paper-title">
                      <b>Labelling Data with Unknown References</b>
                    </div>
                    <div class="paper-misc">
                      <a href="https://arxiv.org/abs/2506.03083">[pdf]</a>
                      <a href="bibtex/unknown.html">[BibTex]</a></b>
                      <!-- <a href="https://github.com/adewynter/awes_laws_and_flaws">[Code]</a></b> -->
                    </div>
                    <div class="paper-authors">
                      Adrian de Wynter
                    </div>
                    <div class="paper-misc">
                      Preprint
                    </div>
                  </div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b>A Multilingual, Culture-First Approach to Addressing Misgendering in LLM Applications</b>
                    </div>
                    <div class="paper-misc">
                      <a href="https://arxiv.org/abs/2503.20302">[pdf]</a>
                      <a href="bibtex/misgendering.html">[BibTex]</a></b>
                      <!-- <a href="https://github.com/adewynter/awes_laws_and_flaws">[Code]</a></b> -->
                    </div>
                    <div class="paper-authors">
                      Sunayana Sitaram, Adrian de Wynter, Isobel McCrum, Qilong Gu, and Si-Qing Chen
                    </div>
                    <div class="paper-misc">
                      Preprint
                    </div>
                  </div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b>If Eleanor Rigby Had Met ChatGPT: A Study on Loneliness in a Post-LLM World</b>
                    </div>
                    <div class="paper-misc">
                      <a href="https://arxiv.org/abs/2412.01617">[pdf]</a>
                      <a href="https://aclanthology.org/2025.acl-long.976/">[BibTex]</a></b>
                      <a href="https://github.com/adewynter/EleanorRigby">[Code]</a></b>
                    </div>
                    <div class="paper-authors">
                      Adrian de Wynter
                    </div>
                    <div class="paper-misc">
                      ACL 2025 Main
                    </div>
                  </div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b>Awes, Laws and Flaws of Today's LLM Research</b>
                    </div>
                    <div class="paper-misc">
                      <a href="https://arxiv.org/abs/2408.15409">[pdf]</a>
                      <a href="https://aclanthology.org/2025.findings-acl.664/">[BibTex]</a></b>
                      <a href="https://github.com/adewynter/awes_laws_and_flaws">[Code]</a></b>
                    </div>
                    <div class="paper-authors">
                      Adrian de Wynter
                    </div>
                    <div class="paper-misc">
                      ACL 2025 Findings
                    </div>
                  </div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b>LLMs Are All You Need</b>
                    </div>
                    <div class="paper-misc">
                      <a href="https://sigbovik.org/2025/proceedings.pdf">[pdf]</a>
                    </div>
                    <div class="paper-authors">
                      Adrian de Wynter
                    </div>
                    <div class="paper-misc">
                      SIGBOVIK 2025 (IKYK)
                    </div>
                  </div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b>Will GPT-4 Run DOOM?</b>
                    </div>
                    <div class="paper-misc">
                      <a href="https://ieeexplore.ieee.org/document/10752360">[pdf]</a>
                      <a href="bibtex/doom.html">[BibTex]</a>
                      <a href="https://github.com/adewynter/Doom">[Code]</a>
                      <a href="Doom.html">[Post]</a>
                    </div>
                    <div class="paper-authors">
                      Adrian de Wynter
                    </div>
                    <div class="paper-misc">
                      IEEE Transactions on Games (2024)
                    </div>
                  </div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b>LLM as a Mastermind: A Survey of Strategic Reasoning with Large Language Models</b>
                    </div>
                    <div class="paper-misc">
                      <a href="https://arxiv.org/pdf/2404.01230.pdf">[pdf]</a>
                      <a href="bibtex/llmmastermind.html">[BibTex]</a></b>
                    </div>
                    <div class="paper-authors">
                      Yadong Zhang, Shaoguang Mao, Tao Ge, Xun Wang, Adrian de Wynter, Yan Xia, Wenshan Wu, Ting Song, Man Lan and Furu Wei
                    </div>
                    <div class="paper-misc">
                      COLM 2024
                    </div>
                  </div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b>Assessing Dialect Fairness and Robustness of Large Language Models in Reasoning Tasks</b>
                    </div>
                    <div class="paper-misc">
                      <a href="https://arxiv.org/abs/2410.11005">[pdf]</a>
                      <a href="https://aclanthology.org/2025.acl-long.317/">[BibTex]</a>
                    </div>
                    <div class="paper-authors">
                      Fangru Lin, Shaoguang Mao, Emanuele La Malfa, Valentin Hofmann, Adrian de Wynter, Xun Wang, Si-Qing Chen, Michael J. Wooldridge, Janet B. Pierrehumbert, Furu Wei
                    </div>
                    <div class="paper-misc">
                      ACL 2025 Main
                    </div>
                  </div>
                  
                  <div class="section-item">
                    <div class="paper-title">
                      <b>RTP-LX: Can LLMs Evaluate Toxicity in Multilingual Scenarios?</b>
                    </div>
                    <div class="paper-misc">
                      <a href="https://ojs.aaai.org/index.php/AAAI/article/view/35011">[pdf]</a>
                      <a href="https://ojs.aaai.org/index.php/AAAI/article/view/35011">[BibTex]</a>
                      <a href="https://huggingface.co/datasets/adewynter/RTP-LX">[Code]</a>
                    </div>
                    <div class="paper-authors">
                      Adrian de Wynter <i>et al.</i>
                    </div>
                    <div class="paper-misc">
                      AAAI 2025
                    </div>
                  </div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b>On Meta-Prompting</b>
                    </div>
                    <div class="paper-misc">
                      <a href="https://arxiv.org/abs/2312.06562">[pdf]</a>
                      <a href="bibtex/metaprompting.html">[BibTex]</a>
                      <a href="https://github.com/adewynter/metaprompting">[Code]</a>
                    </div>
                    <div class="paper-authors">
                      Adrian de Wynter, Xun Wang, Qilong Gu, and Si-Qing Chen
                    </div>
                    <div class="paper-misc">
                      Preprint (2023)
                    </div>
                  </div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b>An Evaluation of LLM Outputs: Discourse and Memorization</b>
                    </div>
                    <div class="paper-misc">
                      <a href="https://www.sciencedirect.com/science/article/pii/S2949719123000213">[pdf]</a>
                      <a href="bibtex/llmeval.html">[BibTex]</a>
                    </div>
                    <div class="paper-authors">
                      Adrian de Wynter, Xun Wang, Alex Sokolov, Qilong Gu, and Si-Qing Chen
                    </div>
                    <div class="paper-misc">
                      The Natural Language Processing Journal
                    </div>
                  </div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b>"I'd Like to Have an Argument, Please": Argumentative Reasoning in Large Language Models</b>
                    </div>
                    <div class="paper-misc">
                      <a href="https://ebooks.iospress.nl/doi/10.3233/FAIA240311">[pdf]</a>
                      <a href="bibtex/argumentation1.html">[BibTex]</a>
                      <a href="https://github.com/adewynter/argumentation-llms">[Code]</a>
                    </div>
                    <div class="paper-authors">
                      Adrian de Wynter and Tangming Yuan
                    </div>
                    <div class="paper-misc">
                      COMMA 2024
                    </div>
                  </div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b>On the Opportunities and Dangers of LLM-Based Evaluation</b>
                    </div>
                    <div class="paper-misc">
                    </div>
                    <div class="paper-authors">
                      Chris Quirk and Adrian de Wynter
                    </div>
                    <div class="paper-misc">
                      Invited talk at the 2023 MLADS Conference
                    </div>
                  </div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b>Are Large Language Model-based Evaluators the Solution to Scaling Up Multilingual Evaluation?</b>
                    </div>
                    <div class="paper-misc">
                      <a href="https://arxiv.org/abs/2309.07462">[pdf]</a>
                      <a href="https://aclanthology.org/2024.findings-eacl.71/">[BibTex]</a>
                    </div>
                    <div class="paper-authors">
                      Rishav Hada, Varun Gumma, Adrian de Wynter, Harshita Diddee, Mohamed Ahmed, Monojit Choudhury, Kalika Bali, and Sunayana Sitaram
                    </div>
                    <div class="paper-misc">
                      EACL 2024
                    </div>
                  </div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b>Turing Completeness and <i>Sid Meier's Civilization</i></b>
                    </div>
                    <div class="paper-misc">
                      <a href="https://ieeexplore.ieee.org/document/9756289">[pdf]</a>
                      <a href="bibtex/civ.html">[BibTex]</a>
                      <a href="https://adewynter.github.io/notes/img/BB3.gif">[The Turing Machine in Action]</a>
                    </div>
                    <div class="paper-authors">
                      Adrian de Wynter
                    </div>
                    <div class="paper-misc">
                      IEEE Transactions on Games
                    </div>
                  </div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b>An Algorithm for Learning Smaller Representations of Models With Scarce Data </b>
                    </div>
                    <div class="paper-misc">
                      <a href="https://link.springer.com/article/10.1007/s41884-024-00153-0">[pdf]</a>
                      <a href="bibtex/agora.html">[BibTex]</a>
                      <a href="https://github.com/alexa/bort">[Code]</a>
                    </div>
                    <div class="paper-authors">
                      Adrian de Wynter
                    </div>
                    <div class="paper-misc">
                      Information Geometry (2024)
                    </div>
                  </div>

              </div><!-- papers-education--desktop -->

              <div><p style="font-family:helvetica; display:flex; justify-content:flex-end"><a href="notes/older_papers.html">More</a></p></div>

            </div><!-- papers-filler -->


          </div><!-- papers -->




          <div class="papers">
              <div class="papers-block">
                <div class="section-label--right">Selected Media Coverage</div>

                <div class="papers-education--desktop">

                  <div>
                    <p></p>
                    <p style="font-family: Helvetica"><i>Some media coverage of the work I do, in case my posts remain as confusing as the original papers.</i></p>
                  </div>


                  <div class="section-item">
                    <div class="paper-title">
                      <b><a href="https://www.tweaktown.com/news/96799/microsoft-scientist-gets-ai-to-play-doom-but-then-issued-warning/index.html">Microsoft scientist gets AI to play DOOM but then issued a warning</a></b>
                    </div>
                    <div class="paper-misc">
                      Some of the coverage of the work I did with DOOM and GPT-4. You can also read about it <a href="https://www.tomshardware.com/tech-industry/artificial-intelligence/gpt-4v-can-play-doom-badly-doesnt-hesitate-to-shoot-humans-and-demons">here (Tom's Hardware)</a>, <a href="https://www.pcmag.com/news/openais-gpt-4-can-play-doom-but-only-like-a-noob">here (PC Mag)</a>, and <a href="https://www.theregister.com/2024/03/11/gpt4_wont_run_doom/">here (The Register)</a>.
                    </div>
                  </div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b><a href="https://www.amazon.science/blog/a-version-of-the-bert-language-model-thats-20-times-as-fast">A version of the BERT language model that’s 20 times as fast</a></b>
                    </div>
                    <div class="paper-misc">
                      Another post edited by Larry Hardesty. This one talks about Bort.
                    </div>
                  </div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b><a href="https://www.infoq.com/articles/state-art-automl/">State of the Art in Automated Machine Learning</a></b>
                    </div>
                    <div class="paper-misc">
                      This is an interview I, along with other researchers, gave for InfoQ around AutoML. It's so interesting to see people of such different backgrounds arriving to the same conclusions :)
                    </div>
                  </div>


                  <div class="section-item">
                    <div class="paper-title">
                      <b><a href="https://www.infoq.com/news/2019/11/alexa-genetic-deep-learning/">Alexa Research Paper Shows Genetic Algorithms Offer Best Solution for Neural Network Optimization</a></b>
                    </div>
                    <div class="paper-misc">
                    This post sums up very nicely my work around NAS/ASP/FA.
                    </div>
                  </div>


                  <div class="section-item">
                    <div class="paper-title">
                      <b><a href="https://venturebeat.com/2019/09/23/amazon-researchers-say-evolutionary-approach-improves-the-selection-of-ai-models/">Amazon researchers say evolutionary approach improves the selection of AI models</a></b>
                    </div>
                    <div class="paper-misc">
                      From Venturebeat.
                    </div>
                  </div>


                  <div class="section-item">
                    <div class="paper-title">
                      <b><a href="https://www.amazon.science/blog/how-to-construct-the-optimal-neural-architecture-for-your-machine-learning-task">How to Construct the Optimal Neural Architecture for Your Machine Learning Task</a></b>
                    </div>
                    <div class="paper-misc">
                      A post edited by the awesome Larry Hardesty.
                    </div>
                  </div>


              </div><!-- media-education--desktop -->

            </div><!-- media-filler -->


          </div><!-- media -->



          <div class="papers">

              <div class="papers-block">
              <p style="font-family:helvetica; display:flex; justify-content:flex-end">Contact: first-initial-full-last-name-including-tussenvoegsel (at) microsoft.com</p>

              <p style="font-family:helvetica; display:flex; justify-content:flex-end">Factoid: my ORCID (326797241) is a prime number; it is expressible as the sum of two squares (1715 and 17996); and it is the square root (hypothenuse) of the sum of two squares (61726280 and 320914791). Yay.</p>
            </div>
          </div>

        </div> <!-- main-text -->

    </div>

  </div> <!-- content -->


  </body>
</html>
