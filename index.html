<!DOCTYPE html>
<html>
  <head>
  <title>Adrian de Wynter</title>
  
  <meta name="google-site-verification" content="UhAhnWA093u8hR6zIezUozC_aTIl1dT1rPX8UEuOdDg" />
  <meta content="Adrian de Wynter" name="author">
  <meta name="keywords" content="Adrian, de Wynter, Adrian de Wynter">
  <meta name="description" content="Adrian de Wynter's home page, updated every two years!">
  <meta content="width=device-width, initial-scale=1.0, user-scalable=no" name="viewport">
  
  <link href="styles/main_index.css" media="screen" rel="stylesheet" type="text/css">
  <link rel="icon" type="image/png" href="img/dewynter.jpg"/>

  </head>

<!-- very loosely taken from Ana Enders' design -- anaenders.com -->
  <body>
    <div class="content">

      <div class="header-wrapper">
        <header>
          <div style="display: flex; justify-content: center; text-align: center; align-items: center;"><h1>Adrian de Wynter</h1>
             
            <p> <br/><br/>.</p>
          </div>
        </header>
      </div>

      <div>
        <div class="banner">
          <ul>
            <li class="slide2"></li>
            <li class="slide1"></li>
          </ul>
        </div>
        <div class="banner2">
          <ul>
          <li class="mslide1"></li>
          <li class="mslide2"></li>
        </ul>
        </div>

        <div class="main-text">
          <div class="about">
            <div class="about-text">

              <p style="font-family:helvetica">I am a principal applied <b>scientist</b> at Microsoft and a <b>researcher</b> (PGR) at the University of York. I work in projects related to <b>natural language</b> understanding/generation and fundamental problems in deep learning, such as <b>reasoning and formal modelling of dialogue</b>, like LLMs.</p>

              <p style="font-family:helvetica">My primary interest is computation, and specifically, the study of <b>reasoning as it relates to humans and machines</b>. 
              My approach is mainly intuitionistic in nature, contrasting with some other formalisms used in this field. In English: algorithms have provable guarantees of complexity and convergence via <em>construction</em>, and this proof must be closely-related to a <em>computable</em> (e.g., realistic, decidable, production) scenario. This gives <b>meaningful answers about complex problems</b>, while also circumventing mathematical results that are rarely seen in practice. For example, we recently used <a href="https://arxiv.org/abs/2312.06562">category theory</a> to prove that some prompting strategies are objectively better than others; and that they would produce more preferrable outcomes by users.</p>
            </div>

            <div class="about-text">

              <p style="font-family:helvetica">I'm a strong proponent of training <b>small and efficient models</b>, as opposed to overspecified networks--which I call <a href="https://www.youtube.com/watch?v=_oNgyUAEv0Q">Jurassic</a> networks. This matters! The power required to train these models translates into tons of carbon emitted into the atmosphere, and it's <a href="https://arxiv.org/abs/1906.02243">devastating</a> to the environment. 
              Although I <a href="https://arxiv.org/pdf/1908.09942.pdf">showed</a> that finding a globally optimal solution to this problem is generally undecidable, I have also <a href="https://arxiv.org/pdf/2010.08512">proved</a> that it is possible to find approximation algorithms that give near-optimal solutions in polynomial time--going as far as <a href="https://arxiv.org/pdf/2010.10499">applying</a> these results to BERT and reaching a (then) state-of-the-art on model compression. This last contribution was later adapted for quantum circuit optimization in a rather fantastic <a href="https://github.com/XanaduAI/QHack2021/issues/73">work</a> by folks at ORNL.</p>

              <p style="font-family:helvetica">Other of my research interests are related to <b>recreational mathematics</b> (especially about games), <b>preserving endangered languages</b>, and applications of <b>LLMs to create inclusive environments</b> to traditionally excluded groups in ML (e.g., neurodiverse individuals such as myself, non-English speakers, etcetera).</p>

              <p style="font-family:Helvetica, Serif; color: #231f20; display:flex; justify-content:flex-end">Last updated: Aug '24.</p>
            </div>
          </div>

          <div class="papers">

              <div class="papers-block">
                <div class="section-label--right">New and Selected Works</div>
                <div class="papers-education--desktop">

                  <div><p></p><p style="font-family: Helvetica"><i>Following Larry Wasserman's <a href="http://stat.cmu.edu/~larry/Peer-Review.pdf">essay</a>, I invite comments on the papers below. Feel free to email me.<br>For a longer, complete list of works see <a href="notes/older_papers.html">here</a>.<br>For how to handle my last name's weird spelling rules, see <a href="notes/tussenvoegsels.html">here</a>.</i></p></div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b>Will GPT-4 Run DOOM?</b>
                    </div>
                    <div class="paper-misc">
                      <a href="https://arxiv.org/abs/2403.05468">[pdf]</a>
                      <a href="bibtex/doom.html">[BibTex]</a>
                      <a href="https://github.com/adewynter/Doom">[Code]</a>
                      <a href="Doom.html">[Post]</a>
                    </div>
                    <div class="paper-authors">
                      Adrian de Wynter
                    </div>
                    <div class="paper-misc">
                      Preprint (2024)
                    </div>
                  </div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b>LLM as a Mastermind: A Survey of Strategic Reasoning with Large Language Models</b>
                    </div>
                    <div class="paper-misc">
                      <a href="https://arxiv.org/pdf/2404.01230.pdf">[pdf]</a>
                      <a href="bibtex/llmmastermind.html">[BibTex]</a></b>
                    </div>
                    <div class="paper-authors">
                      Yadong Zhang, Shaoguang Mao, Tao Ge, Xun Wang, Adrian de Wynter, Yan Xia, Wenshan Wu, Ting Song, Man Lan and Furu Wei
                    </div>
                    <div class="paper-misc">
                      COLM 2024
                    </div>
                  </div>
                  
                  <div class="section-item">
                    <div class="paper-title">
                      <b>RTP-LX: Can LLMs Evaluate Toxicity in Multilingual Scenarios?</b>
                    </div>
                    <div class="paper-misc">
                      <a href="https://arxiv.org/abs//2404.14397.pdf">[pdf]</a>
                      <a href="bibtex/rtplx.html">[BibTex]</a>
                      <a href="https://github.com/microsoft/RTP-LX">[Code]</a>
                    </div>
                    <div class="paper-authors">
                      Adrian de Wynter, Ishaan Watts, <i>et al.</i>
                    </div>
                    <div class="paper-misc">
                      Preprint (2024)
                    </div>
                  </div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b>On Meta-Prompting</b>
                    </div>
                    <div class="paper-misc">
                      <a href="https://arxiv.org/abs/2312.06562">[pdf]</a>
                      <a href="bibtex/metaprompting.html">[BibTex]</a>
                      <a href="https://github.com/adewynter/metaprompting">[Code]</a>
                    </div>
                    <div class="paper-authors">
                      Adrian de Wynter, Xun Wang, Qilong Gu, and Si-Qing Chen
                    </div>
                    <div class="paper-misc">
                      Preprint (2023)
                    </div>
                  </div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b>An Evaluation of LLM Outputs: Discourse and Memorization</b>
                    </div>
                    <div class="paper-misc">
                      <a href="https://www.sciencedirect.com/science/article/pii/S2949719123000213">[pdf]</a>
                      <a href="bibtex/llmeval.html">[BibTex]</a>
                    </div>
                    <div class="paper-authors">
                      Adrian de Wynter, Xun Wang, Alex Sokolov, Qilong Gu, and Si-Qing Chen
                    </div>
                    <div class="paper-misc">
                      The Natural Language Processing Journal
                    </div>
                  </div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b>"I'd Like to Have an Argument, Please": Argumentative Reasoning in Large Language Models</b>
                    </div>
                    <div class="paper-misc">
                      <a href="https/:/arxiv.org/abs/2309.16938">[pdf]</a>
                      <a href="bibtex/argumentation1.html">[BibTex]</a>
                      <a href="https://github.com/adewynter/argumentation-llms">[Code]</a>
                    </div>
                    <div class="paper-authors">
                      Adrian de Wynter and Tangming Yuan
                    </div>
                    <div class="paper-misc">
                      COMMA 2024
                    </div>
                  </div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b>On the Opportunities and Dangers of LLM-Based Evaluation</b>
                    </div>
                    <div class="paper-misc">
                    </div>
                    <div class="paper-authors">
                      Chris Quirk and Adrian de Wynter
                    </div>
                    <div class="paper-misc">
                      Invited talk at the 2023 MLADS Conference
                    </div>
                  </div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b>Are Large Language Model-based Evaluators the Solution to Scaling Up Multilingual Evaluation?</b>
                    </div>
                    <div class="paper-misc">
                      <a href="https://arxiv.org/abs/2309.07462">[pdf]</a>
                      <a href="https://aclanthology.org/2024.findings-eacl.71/">[BibTex]</a>
                    </div>
                    <div class="paper-authors">
                      Rishav Hada, Varun Gumma, Adrian de Wynter, Harshita Diddee, Mohamed Ahmed, Monojit Choudhury, Kalika Bali, and Sunayana Sitaram
                    </div>
                    <div class="paper-misc">
                      EACL 2024
                    </div>
                  </div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b>Turing Completeness and <i>Sid Meier's Civilization</i></b>
                    </div>
                    <div class="paper-misc">
                      <a href="https://ieeexplore.ieee.org/document/9756289">[pdf]</a>
                      <a href="bibtex/civ.html">[BibTex]</a>
                      <a href="https://adewynter.github.io/notes/img/BB3.gif">[The Turing Machine in Action]</a>
                    </div>
                    <div class="paper-authors">
                      Adrian de Wynter
                    </div>
                    <div class="paper-misc">
                      IEEE Transactions on Games
                    </div>
                  </div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b>Optimal Subarchitecture Extraction for BERT</b>
                    </div>
                    <div class="paper-misc">
                      <a href="https://arxiv.org/pdf/2010.10499">[pdf]</a>
                      <a href="bibtex/osebert.html">[BibTex]</a>
                      <a href="https://github.com/alexa/bort">[Code]</a>
                    </div>
                    <div class="paper-authors">
                      Adrian de Wynter and Daniel J. Perry
                    </div>
                    <div class="paper-misc">
                      Preprint (2020)
                    </div>
                  </div>

              </div><!-- papers-education--desktop -->

              <div><p style="font-family:helvetica; display:flex; justify-content:flex-end"><a href="notes/older_papers.html">More</a></p></div>

            </div><!-- papers-filler -->


          </div><!-- papers -->




          <div class="papers">
              <div class="papers-block">
                <div class="section-label--right">Selected Media Coverage</div>

                <div class="papers-education--desktop">

                  <div>
                    <p></p>
                    <p style="font-family: Helvetica"><i>Some media coverage of the work I do, in case my posts remain as confusing as the original papers.</i></p>
                  </div>


                  <div class="section-item">
                    <div class="paper-title">
                      <b><a href="https://www.tweaktown.com/news/96799/microsoft-scientist-gets-ai-to-play-doom-but-then-issued-warning/index.html">Microsoft scientist gets AI to play DOOM but then issued a warning</a></b>
                    </div>
                    <div class="paper-misc">
                      Some of the coverage of the work I did with DOOM and GPT-4. You can also read about it <a href="https://www.tomshardware.com/tech-industry/artificial-intelligence/gpt-4v-can-play-doom-badly-doesnt-hesitate-to-shoot-humans-and-demons">here (Tom's Hardware)</a>, <a href="https://www.pcmag.com/news/openais-gpt-4-can-play-doom-but-only-like-a-noob">here (PC Mag)</a>, and <a href="https://www.theregister.com/2024/03/11/gpt4_wont_run_doom/">here (The Register)</a>.
                    </div>
                  </div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b><a href="https://www.amazon.science/blog/a-version-of-the-bert-language-model-thats-20-times-as-fast">A version of the BERT language model that’s 20 times as fast</a></b>
                    </div>
                    <div class="paper-misc">
                      Another post edited by Larry Hardesty. This one talks about Bort.
                    </div>
                  </div>

                  <div class="section-item">
                    <div class="paper-title">
                      <b><a href="https://www.infoq.com/articles/state-art-automl/">State of the Art in Automated Machine Learning</a></b>
                    </div>
                    <div class="paper-misc">
                      This is an interview I, along with other researchers, gave for InfoQ around AutoML. It's so interesting to see people of such different backgrounds arriving to the same conclusions :)
                    </div>
                  </div>


                  <div class="section-item">
                    <div class="paper-title">
                      <b><a href="https://www.infoq.com/news/2019/11/alexa-genetic-deep-learning/">Alexa Research Paper Shows Genetic Algorithms Offer Best Solution for Neural Network Optimization</a></b>
                    </div>
                    <div class="paper-misc">
                    This post sums up very nicely my work around NAS/ASP/FA.
                    </div>
                  </div>


                  <div class="section-item">
                    <div class="paper-title">
                      <b><a href="https://venturebeat.com/2019/09/23/amazon-researchers-say-evolutionary-approach-improves-the-selection-of-ai-models/">Amazon researchers say evolutionary approach improves the selection of AI models</a></b>
                    </div>
                    <div class="paper-misc">
                      From Venturebeat.
                    </div>
                  </div>


                  <div class="section-item">
                    <div class="paper-title">
                      <b><a href="https://www.amazon.science/blog/how-to-construct-the-optimal-neural-architecture-for-your-machine-learning-task">How to Construct the Optimal Neural Architecture for Your Machine Learning Task</a></b>
                    </div>
                    <div class="paper-misc">
                      A post edited by the awesome Larry Hardesty.
                    </div>
                  </div>


              </div><!-- media-education--desktop -->

            </div><!-- media-filler -->


          </div><!-- media -->



          <div class="papers">

              <div class="papers-block">
              <p style="font-family:helvetica; display:flex; justify-content:flex-end">Contact: first-initial-full-last-name-including-tussenvoegsel (at) microsoft.com</p>

              <p style="font-family:helvetica; display:flex; justify-content:flex-end">Factoid: my ORCID (326797241) is a prime number; it is expressible as the sum of two squares (1715 and 17996); and it is the square root (hypothenuse) of the sum of two squares (61726280 and 320914791). Yay.</p>
            </div>
          </div>

        </div> <!-- main-text -->

    </div>

  </div> <!-- content -->


  </body>
</html>
