<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="keywords" content="Adrian, de Wynter, Adrian de Wynter, Bort">
  <meta name="description" content="Adrian de Wynter's home page.">
  <meta name="google-site-verification" content="UhAhnWA093u8hR6zIezUozC_aTIl1dT1rPX8UEuOdDg" />
  <title style="font-family:helvetica">Adrian de Wynter</title>
  <meta name="viewport" content="width=device-width">
  <link rel="icon" type="image/png" href="dewynter.jpg"/>
  <style>
    p {
      margin-top: 2.5%;
      margin-right: 2.5%;
      margin-left: 2.5%;
      margin-bottom: 2.5%;
    }
    h2 {
      font-family:helvetica;
      margin-top: 2.5%;
    }
  </style>
</head>

<body>

  <div class="page-content">
    <div class="wrap">
    <h1 >Adrian de Wynter<a href="dewynter.jpg" target="_blank"><img style="float:right; width:200px; margin-left: 5%" src="dewynter.jpg"/></a></h1>
    <h>/ˈeɪdrɪən təʋɪnˈtər/</p>

    <p>I am an Applied Scientist in Amazon Alexa's Secure AI Foundations (SAIF) organization.</p>
    <p>My primary research interest lies within computation, and (mostly) machine learning. At the moment I am working on projects addressing natural language understanding and neural architecture search. I mainly explore the computational limits of meta-learning, as it is applied to automated model design and training. 
    I'm a strong proponent of training small and efficient models, as opposed to overspecified networks--which I call <a href="https://www.youtube.com/watch?v=_oNgyUAEv0Q">Jurassic</a> networks--via the development of algorithms with provable optimality guarantees. Here "efficient" would mean "only as big as needed for the task". This is important because the power required to train these huge models can be translated directly into tons of carbon emitted into the atmosphere, and it's <a href="https://arxiv.org/abs/1906.02243">devastating</a> to the environment.</p>

    <p> Although I <a href="https://arxiv.org/pdf/1908.09942.pdf">showed</a> that finding a globally optimal solution to this problem is undecidable in its general form, I have also <a href="https://arxiv.org/pdf/2010.08512">proved</a> that for several interesting cases it is possible to find approximation algorithms that give near-optimal solutions in polynomial time--going as far as <a href="https://arxiv.org/pdf/2010.10499">applying</a> these results to the well-known BERT language model and reaching a new state-of-the-art on model compression.</p>

    <p>Other research interests of mine are related to the computational aspects of memes (seriously); and, concretely, their dynamics.</p>

<hr>
<h2>Posts</h2>
<p> I've found it useful to have a series of "posts" on the work I do, to make it more accessible and share my passion for mathematics.</p>
<ul>
  <li><a href="https://adewynter.github.io/notes/bort_algorithms_and_applications.html">Bort: Algorithms and Applications</a>: a post on the algorithms used to obtain Bort, an optimally compressed version of the BERT language model. This can be viewed as a summary of my papers "Optimal Subarchitecture Extraction for BERT", "An Algorithm for Learning Smaller Representations of Models With Scarce Data", and "An Approximation Algorithm for Optimal Subarchitecture Extraction", albeit less concise than these titles, if you can believe it.</li>
</ul>

<hr>
<h2>Publications and Talks</h2>
<p>Following Larry Wasserman's <a href="http://stat.cmu.edu/~larry/Peer-Review.pdf">essay</a>, I invite comments on the papers below. Feel free to email me.</p>

  <table>
    <tr>
      <td><b>2020</b></td>
      <td>
        <b>Optimal Subarchitecture Extraction for BERT</b><br />Adrian de Wynter and Daniel J. Perry<br />
        Preprint<br />
        <a href="https://arxiv.org/pdf/2010.10499">[pdf]</a>
        <a href="bibtex/osebert.html">[BibTex]</a>
        <a href="https://github.com/alexa/bort">[Code]</a>
      </td>
    </tr>

    <tr>
      <td><b>2020</b></td>
      <td>
        <b>An Algorithm for Learning Smaller Representations of Models With Scarce Data</b><br />Adrian de Wynter<br />
        Preprint<br />
        <a href="https://arxiv.org/pdf/2010.07990">[pdf]</a>
        <a href="bibtex/agora.html">[BibTex]</a>
      </td>
    </tr>

    <tr>
      <td><b>2020</b></td>
      <td>
        <b>An Approximation Algorithm for Optimal Subarchitecture Extraction</b><br />Adrian de Wynter<br />
        Preprint<br />
        <a href="https://arxiv.org/pdf/2010.08512">[pdf]</a>
        <a href="bibtex/ose.html">[BibTex]</a>
      </td>
    </tr>

    <tr>
      <td><b>2020</b></td>
      <td>
        <b>Mischief: A Simple Black-Box Attack Against Transformer Architectures</b><br />Adrian de Wynter<br />
        Preprint<br />
        <a href="https://arxiv.org/pdf/2010.08542">[pdf]</a>
        <a href="bibtex/mischief.html">[BibTex]</a>
      </td>
    </tr>

    <tr>
      <td><b>2020</b></td>
      <td>
        <b>Harder Performance Measures for Language Models</b>
        <br/>Adrian de Wynter
        <br/>Invited talk at the 2020 Alexa Prize Summit (UPDATE: canceled due to COVID-19, stay safe!)<br />
      </td>
    </tr>

    <tr>
      <td><b>2019</b></td>
      <td>
        <b>On the Bounds of Function Approximations</b><br />Adrian de Wynter<br />ICANN 2019 (oral presentation)<br />
        <a href="https://arxiv.org/pdf/1908.09942.pdf">[pdf]</a>
        <a href="bibtex/fa.html">[BibTex]</a>
      </td>
    </tr>

    <tr>
      <td><b>2019</b></td>
      <td>
        <b>Leveraging External Knowledge for Out-Of-Vocabulary Entity Labeling</b><br />Adrian de Wynter and Lambert Mathias<br />Preprint<br />
        <a href="https://arxiv.org/pdf/1908.09936.pdf">[pdf]</a>
        <a href="bibtex/oov.html">[BibTex]</a>
      </td>
    </tr>

</table>

 <hr> 
<h2>Service</h2>
<table>
  <tr>
    <td><b>2020</b></td>
    <td>
      <b>International Conference on Artificial Neural Networks </b>
      <br/>Adrian de Wynter
      <br/>Reviewer<br />
    </td>
  </tr>

  <tr>
    <td><b>2020</b></td>
    <td>
      <b>Annual Conference of the Association for Computational Linguistics </b>
      <br/>Adrian de Wynter
      <br/>Reviewer<br />
    </td>
  </tr>

</table>



<p>Contact: last-name-minus-first-e (at) amazon.com<br/>
  Last updated: Jan '21.<br/></p>

<font size=0 color=#ffffff>Adrian, de Wynter, Adrian de Wynter, Bort, Agora</font>

</body>

</html>